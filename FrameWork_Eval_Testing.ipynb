{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Metrics with SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Movielens import MovieLens\n",
    "from surprise import SVD\n",
    "from surprise import KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from RecommenderMetrics import RecommenderMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading movie ratings...\")\n",
    "data = ml.loadMovieLensLatestSmall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing movie popularity ranks so we can measure novelty later...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing movie popularity ranks so we can measure novelty later...\")\n",
    "rankings = ml.getPopularityRanks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing item similarities so we can measure diversity later...\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7fbe73b00ed0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Computing item similarities so we can measure diversity later...\")\n",
    "fullTrainSet = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "simsAlgo = KNNBaseline(sim_options=sim_options)\n",
    "simsAlgo.fit(fullTrainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building recommendation model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fbe73c16790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nBuilding recommendation model...\")\n",
    "trainSet, testSet = train_test_split(data, test_size=.25, random_state=1)\n",
    "\n",
    "algo = SVD(random_state=10)\n",
    "algo.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing recommendations...\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing recommendations...\")\n",
    "predictions = algo.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating accuracy of model...\n",
      "RMSE:  0.87790565300794\n",
      "MAE:  0.6731720779996845\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating accuracy of model...\")\n",
    "print(\"RMSE: \", RecommenderMetrics.RMSE(predictions))\n",
    "print(\"MAE: \", RecommenderMetrics.MAE(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating top-10 recommendations...\n",
      "Computing recommendations with leave-one-out...\n",
      "Predict ratings for left-out set...\n",
      "Predict all missing ratings...\n",
      "Compute top 10 recs per user...\n",
      "\n",
      "Hit Rate:  0.036065573770491806\n",
      "\n",
      "rHR (Hit Rate by Rating value): \n",
      "2.5 0.06666666666666667\n",
      "3.0 0.008695652173913044\n",
      "4.0 0.044444444444444446\n",
      "4.5 0.09433962264150944\n",
      "5.0 0.056910569105691054\n",
      "\n",
      "cHR (Cumulative Hit Rate, rating >= 4):  0.056179775280898875\n",
      "\n",
      "ARHR (Average Reciprocal Hit Rank):  0.013333333333333332\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating top-10 recommendations...\")\n",
    "\n",
    "# Set aside one rating per user for testing\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainSet, testSet in LOOCV.split(data):\n",
    "    print(\"Computing recommendations with leave-one-out...\")\n",
    "\n",
    "    # Train model without left-out ratings\n",
    "    algo.fit(trainSet)\n",
    "\n",
    "    # Predicts ratings for left-out ratings only\n",
    "    print(\"Predict ratings for left-out set...\")\n",
    "    leftOutPredictions = algo.test(testSet)\n",
    "\n",
    "    # Build predictions for all ratings not in the training set\n",
    "    print(\"Predict all missing ratings...\")\n",
    "    bigTestSet = trainSet.build_anti_testset()\n",
    "    allPredictions = algo.test(bigTestSet)\n",
    "\n",
    "    # Compute top 10 recs for each user\n",
    "    print(\"Compute top 10 recs per user...\")\n",
    "    topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n=10)\n",
    "\n",
    "    # See how often we recommended a movie the user actually rated\n",
    "    print(\"\\nHit Rate: \", RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions))\n",
    "\n",
    "    # Break down hit rate by rating value\n",
    "    print(\"\\nrHR (Hit Rate by Rating value): \")\n",
    "    RecommenderMetrics.RatingHitRate(topNPredicted, leftOutPredictions)\n",
    "\n",
    "    # See how often we recommended a movie the user actually liked\n",
    "    print(\"\\ncHR (Cumulative Hit Rate, rating >= 4): \", RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions, 4.0))\n",
    "\n",
    "    # Compute ARHR\n",
    "    print(\"\\nARHR (Average Reciprocal Hit Rank): \", RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing complete recommendations, no hold outs...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing complete recommendations, no hold outs...\")\n",
    "algo.fit(fullTrainSet)\n",
    "bigTestSet = fullTrainSet.build_anti_testset()\n",
    "allPredictions = algo.test(bigTestSet)\n",
    "topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User coverage:  0.9245901639344263\n"
     ]
    }
   ],
   "source": [
    "# Print user coverage with a minimum predicted rating of 4.0:\n",
    "print(\"\\nUser coverage: \", RecommenderMetrics.UserCoverage(topNPredicted, fullTrainSet.n_users, ratingThreshold=4.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Diversity:  0.9642412821104059\n"
     ]
    }
   ],
   "source": [
    "# Measure diversity of recommendations:\n",
    "print(\"Diversity: \", RecommenderMetrics.Diversity(topNPredicted, simsAlgo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Novelty (average popularity rank):  504.3873857062885\n"
     ]
    }
   ],
   "source": [
    "# Measure novelty (average popularity rank of recommendations):\n",
    "print(\"\\nNovelty (average popularity rank): \", RecommenderMetrics.Novelty(topNPredicted, rankings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor\n",
    "from Evaluator import Evaluator\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def LoadMovieLensData():\n",
    "    ml = MovieLens()\n",
    "    print(\"Loading movie ratings...\")\n",
    "    data = ml.loadMovieLensLatestSmall()\n",
    "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
    "    rankings = ml.getPopularityRanks()\n",
    "    return (data, rankings)\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n"
     ]
    }
   ],
   "source": [
    "# Load data set (user x movie titles, rankings) for the recommender algorithm.\n",
    "(evaluationData, rankings) = LoadMovieLensData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Construct an Evaluator object to evaluate chosen models.\n",
    "evaluator = Evaluator(evaluationData, rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the SVD (Singular Value Decomposition) model\n",
    "SVDAlgorithm = SVD(random_state=10)\n",
    "evaluator.AddAlgorithm(SVDAlgorithm, \"SVD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make random baseline recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  SVD ...\n",
      "Evaluating accuracy...\n",
      "Evaluating top-N with leave-one-out...\n",
      "Computing hit-rate and rank metrics...\n",
      "Computing recommendations with full data set...\n",
      "Analyzing coverage, diversity, and novelty...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Evaluating top-N with leave-one-out...\n",
      "Computing hit-rate and rank metrics...\n",
      "Computing recommendations with full data set...\n",
      "Analyzing coverage, diversity, and novelty...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE        HR         cHR        ARHR       Coverage   Diversity  Novelty   \n",
      "SVD        0.8779     0.6732     0.0361     0.0361     0.0133     0.9246     0.0314     504.3874  \n",
      "Random     1.4227     1.1375     0.0180     0.0180     0.0090     1.0000     0.0535     843.9634  \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\n",
      "cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\n",
      "ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\n",
      "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
      "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
      "           for a given user. Higher means more diverse.\n",
      "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model and print recommendation evaluation metrics.\n",
    "evaluator.Evaluate(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie ratings...\n",
      "\n",
      "Computing movie popularity ranks so we can measure novelty later...\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "Evaluating  ContentKNN ...\n",
      "Evaluating accuracy...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  8775\n",
      "100  of  8775\n",
      "200  of  8775\n",
      "300  of  8775\n",
      "400  of  8775\n",
      "500  of  8775\n",
      "600  of  8775\n",
      "700  of  8775\n",
      "800  of  8775\n",
      "900  of  8775\n",
      "1000  of  8775\n",
      "1100  of  8775\n",
      "1200  of  8775\n",
      "1300  of  8775\n",
      "1400  of  8775\n",
      "1500  of  8775\n",
      "1600  of  8775\n",
      "1700  of  8775\n",
      "1800  of  8775\n",
      "1900  of  8775\n",
      "2000  of  8775\n",
      "2100  of  8775\n",
      "2200  of  8775\n",
      "2300  of  8775\n",
      "2400  of  8775\n",
      "2500  of  8775\n",
      "2600  of  8775\n",
      "2700  of  8775\n",
      "2800  of  8775\n",
      "2900  of  8775\n",
      "3000  of  8775\n",
      "3100  of  8775\n",
      "3200  of  8775\n",
      "3300  of  8775\n",
      "3400  of  8775\n",
      "3500  of  8775\n",
      "3600  of  8775\n",
      "3700  of  8775\n",
      "3800  of  8775\n",
      "3900  of  8775\n",
      "4000  of  8775\n",
      "4100  of  8775\n",
      "4200  of  8775\n",
      "4300  of  8775\n",
      "4400  of  8775\n",
      "4500  of  8775\n",
      "4600  of  8775\n",
      "4700  of  8775\n",
      "4800  of  8775\n",
      "4900  of  8775\n",
      "5000  of  8775\n",
      "5100  of  8775\n",
      "5200  of  8775\n",
      "5300  of  8775\n",
      "5400  of  8775\n",
      "5500  of  8775\n",
      "5600  of  8775\n",
      "5700  of  8775\n",
      "5800  of  8775\n",
      "5900  of  8775\n",
      "6000  of  8775\n",
      "6100  of  8775\n",
      "6200  of  8775\n",
      "6300  of  8775\n",
      "6400  of  8775\n",
      "6500  of  8775\n",
      "6600  of  8775\n",
      "6700  of  8775\n",
      "6800  of  8775\n",
      "6900  of  8775\n",
      "7000  of  8775\n",
      "7100  of  8775\n",
      "7200  of  8775\n",
      "7300  of  8775\n",
      "7400  of  8775\n",
      "7500  of  8775\n",
      "7600  of  8775\n",
      "7700  of  8775\n",
      "7800  of  8775\n",
      "7900  of  8775\n",
      "8000  of  8775\n",
      "8100  of  8775\n",
      "8200  of  8775\n",
      "8300  of  8775\n",
      "8400  of  8775\n",
      "8500  of  8775\n",
      "8600  of  8775\n",
      "8700  of  8775\n",
      "...done.\n",
      "Analysis complete.\n",
      "Evaluating  Random ...\n",
      "Evaluating accuracy...\n",
      "Analysis complete.\n",
      "\n",
      "\n",
      "Algorithm  RMSE       MAE       \n",
      "ContentKNN 0.9055     0.6983    \n",
      "Random     1.4283     1.1414    \n",
      "\n",
      "Legend:\n",
      "\n",
      "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
      "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Rob Roy (1995) 5\n",
      "Desperado (1995) 5\n",
      "So I Married an Axe Murderer (1993) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Dumbo (1941) 5\n",
      "That Thing You Do! (1996) 5\n",
      "Ghost and the Darkness, The (1996) 5\n",
      "Alien (1979) 5\n",
      "Quiet Man, The (1952) 5\n",
      "Indiana Jones and the Last Crusade (1989) 5\n",
      "\n",
      "Using recommender  ContentKNN\n",
      "\n",
      "Building recommendation model...\n",
      "Computing content-based similarity matrix...\n",
      "0  of  9724\n",
      "100  of  9724\n",
      "200  of  9724\n",
      "300  of  9724\n",
      "400  of  9724\n",
      "500  of  9724\n",
      "600  of  9724\n",
      "700  of  9724\n",
      "800  of  9724\n",
      "900  of  9724\n",
      "1000  of  9724\n",
      "1100  of  9724\n",
      "1200  of  9724\n",
      "1300  of  9724\n",
      "1400  of  9724\n",
      "1500  of  9724\n",
      "1600  of  9724\n",
      "1700  of  9724\n",
      "1800  of  9724\n",
      "1900  of  9724\n",
      "2000  of  9724\n",
      "2100  of  9724\n",
      "2200  of  9724\n",
      "2300  of  9724\n",
      "2400  of  9724\n",
      "2500  of  9724\n",
      "2600  of  9724\n",
      "2700  of  9724\n",
      "2800  of  9724\n",
      "2900  of  9724\n",
      "3000  of  9724\n",
      "3100  of  9724\n",
      "3200  of  9724\n",
      "3300  of  9724\n",
      "3400  of  9724\n",
      "3500  of  9724\n",
      "3600  of  9724\n",
      "3700  of  9724\n",
      "3800  of  9724\n",
      "3900  of  9724\n",
      "4000  of  9724\n",
      "4100  of  9724\n",
      "4200  of  9724\n",
      "4300  of  9724\n",
      "4400  of  9724\n",
      "4500  of  9724\n",
      "4600  of  9724\n",
      "4700  of  9724\n",
      "4800  of  9724\n",
      "4900  of  9724\n",
      "5000  of  9724\n",
      "5100  of  9724\n",
      "5200  of  9724\n",
      "5300  of  9724\n",
      "5400  of  9724\n",
      "5500  of  9724\n",
      "5600  of  9724\n",
      "5700  of  9724\n",
      "5800  of  9724\n",
      "5900  of  9724\n",
      "6000  of  9724\n",
      "6100  of  9724\n",
      "6200  of  9724\n",
      "6300  of  9724\n",
      "6400  of  9724\n",
      "6500  of  9724\n",
      "6600  of  9724\n",
      "6700  of  9724\n",
      "6800  of  9724\n",
      "6900  of  9724\n",
      "7000  of  9724\n",
      "7100  of  9724\n",
      "7200  of  9724\n",
      "7300  of  9724\n",
      "7400  of  9724\n",
      "7500  of  9724\n",
      "7600  of  9724\n",
      "7700  of  9724\n",
      "7800  of  9724\n",
      "7900  of  9724\n",
      "8000  of  9724\n",
      "8100  of  9724\n",
      "8200  of  9724\n",
      "8300  of  9724\n",
      "8400  of  9724\n",
      "8500  of  9724\n",
      "8600  of  9724\n",
      "8700  of  9724\n",
      "8800  of  9724\n",
      "8900  of  9724\n",
      "9000  of  9724\n",
      "9100  of  9724\n",
      "9200  of  9724\n",
      "9300  of  9724\n",
      "9400  of  9724\n",
      "9500  of  9724\n",
      "9600  of  9724\n",
      "9700  of  9724\n",
      "...done.\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Pinocchio (1940) 5\n",
      "James and the Giant Peach (1996) 5\n",
      "Wizard of Oz, The (1939) 5\n",
      "Escape to Witch Mountain (1975) 5\n",
      "Winnie the Pooh and the Blustery Day (1968) 5\n",
      "Three Caballeros, The (1945) 5\n",
      "Sword in the Stone, The (1963) 5\n",
      "Pete's Dragon (1977) 5\n",
      "Bedknobs and Broomsticks (1971) 5\n",
      "Alice in Wonderland (1951) 5\n",
      "\n",
      "Using recommender  Random\n",
      "\n",
      "Building recommendation model...\n",
      "Computing recommendations...\n",
      "\n",
      "We recommend:\n",
      "Full Metal Jacket (1987) 5\n",
      "Sneakers (1992) 5\n",
      "Newton Boys, The (1998) 5\n",
      "Psycho (1998) 5\n",
      "Dick Tracy (1990) 5\n",
      "Superman II (1980) 5\n",
      "Frankenstein (1931) 5\n",
      "Who Framed Roger Rabbit? (1988) 5\n",
      "Live and Let Die (1973) 5\n",
      "Green Mile, The (1999) 5\n"
     ]
    }
   ],
   "source": [
    "from MovieLens import MovieLens\n",
    "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
    "from Evaluator import Evaluator\n",
    "from surprise import NormalPredictor\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def LoadMovieLensData():\n",
    "    ml = MovieLens()\n",
    "    print(\"Loading movie ratings...\")\n",
    "    data = ml.loadMovieLensLatestSmall()\n",
    "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
    "    rankings = ml.getPopularityRanks()\n",
    "    return (ml, data, rankings)\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Load up common data set for the recommender algorithm.\n",
    "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
    "\n",
    "# Construct an Evaluator to evaluate chosen models (KNN, random).\n",
    "evaluator = Evaluator(evaluationData, rankings)\n",
    "\n",
    "# Initialize content-based KNN. By default the algorithm creates 40 clusters.\n",
    "contentKNN = ContentKNNAlgorithm()\n",
    "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
    "\n",
    "# Just make random recommendations\n",
    "Random = NormalPredictor()\n",
    "evaluator.AddAlgorithm(Random, \"Random\")\n",
    "\n",
    "evaluator.Evaluate(False)\n",
    "\n",
    "evaluator.SampleTopNRecs(ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run through the recommendation with the same framework. The steps here are similar to the above when I tested the recommendation evaluation framework. The difference here is that instead of evaluating the SVD algorithm against a random one, I am evaluating a new ContentKNN algorithm against random recommendations. Also I dont compute the top-N recommender metrics and only look at accuracy but will sample the top-N recommendations for user 85 to get a feel of how the system is working.\n",
    "\n",
    "The main point of this test is demonstrate/test the application of the ContentKNN algorithm as a derived class from surprise library algo base-class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood based recommendations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**User-based collaborative filtering**\n",
    "\n",
    "The idea behind user-based collaborative filtering is simple is to find other users similar to yourself, based on their ratings history, and then recommend stuff they liked that you haven't seen yet. Lets implement this collaborative filtering technique with my framework below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MovieLens import MovieLens\n",
    "from surprise import KNNBasic\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "        \n",
    "# Select test user with inner user id 86\n",
    "testSubject = '86'\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data set and compile training set.\n",
    "ml = MovieLens()\n",
    "data = ml.loadMovieLensLatestSmall()\n",
    "trainSet = data.build_full_trainset()\n",
    "\n",
    "# Not initializing a test set here since I only want to generate top-n recommendations and dont care about \n",
    "# predicting user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify cosine similarity as our similarity metric and that we want user-user similarities.\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with tunings, fit to data and compute similarities.\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top N similar users to our test subject\n",
    "# (alternate approach would be to select users up to some similarity threshold)\n",
    "testUserInnerID = trainSet.to_inner_uid(testSubject)\n",
    "similarityRow = simsMatrix[testUserInnerID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile list of similar users.\n",
    "similarUsers = []\n",
    "for innerID, score in enumerate(similarityRow):\n",
    "    if (innerID != testUserInnerID):\n",
    "        similarUsers.append( (innerID, score) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quickly sort all users by similarity to test user 86 and extract the top K-neighbors.\n",
    "kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movies they rated, and add up ratings for movie, weighted by user similarity\n",
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary containing the movies the user has already seen so that we can exclude them.\n",
    "watched = {}\n",
    "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Things I Hate About You (1999) 2.7\n",
      "Full Metal Jacket (1987) 2.2\n",
      "Chinatown (1974) 2.2\n",
      "Payback (1999) 2.0\n",
      "Maltese Falcon, The (1941) 1.8\n",
      "Alien (1979) 1.8\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964) 1.6\n",
      "L.A. Confidential (1997) 1.6\n",
      "Lock, Stock & Two Smoking Barrels (1998) 1.6\n",
      "Kill Bill: Vol. 1 (2003) 1.5\n",
      "Young Frankenstein (1974) 1.5\n"
     ]
    }
   ],
   "source": [
    "# Get top-rated items from similar users:\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainSet.to_raw_iid(itemID)\n",
    "        print(ml.getMovieName(int(movieID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Item-based collaborative filtering**\n",
    "\n",
    "Another way to do collaborative filtering instead of looking for other people similar to a user and recommending what a similar user liked, we can look at items a user liked and recommend items similar to those a user has liked.\n",
    "\n",
    "There are a few reasons that using similairites between items can be better than similarities between people: \n",
    "\n",
    "- Items tend to be more permanent in nature than people in the sense that a movie will always be a movie but peoples taste may change quickly over the course of their lives. So focusing on the similarities between unchangeing objects can produce better results than looking at similiarites between people where one may have liked something this week but be looking at something totally different next week.\n",
    "\n",
    "\n",
    "- Because an item similarity matrix wont change as often as a user similarity matrix, they dont need to be computed as often.\n",
    "\n",
    "\n",
    "- There are typically far less items to deal with than people. Whichever company using a system such as this one, probably has a relatively small product catalog compared to the number of customers or users they have. This makes a 2D matrix mapping item similarity scores between every item in a catalog much smaller than a mapping of similarities between every user visiting your site. Not only is it easier to store the matrix but much faster to compute aswell. When dealing with massive systems like Amazon's or Netflix's, I imagine computational efficiency is very important, not only does it require fewer resources, it means that you can regenerate similarities between items more often, making your system more responsive when new items are introduced.\n",
    "\n",
    "\n",
    "- Makes for better experiences for new users because as soon as a new user comes to a website, as soon as they have indicated interest in one thing the system can begin to produce a more tailored list of product recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test framework for Item-based collaborative filtering.\n",
    "\n",
    "testSubject = '85'\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data set and compile training set.\n",
    "\n",
    "ml = MovieLens()\n",
    "data = ml.loadMovieLensLatestSmall()\n",
    "trainSet = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify cosine similarity as our similarity metric and compute over item-item pairs as opposed to user-user pairs.\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with tunings, fit to data and compute similarities.\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user id to raw user id.\n",
    "\n",
    "testUserInnerID = trainSet.to_inner_uid(testSubject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top N items the test user rated.\n",
    "\n",
    "testUserRatings = trainSet.ur[testUserInnerID]\n",
    "kNeighbors = heapq.nlargest(k, testUserRatings, key=lambda t: t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar items to stuff our user liked (weighted by rating)\n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating / 5.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dictionary of stuff the user has already seen so that we can exclude them in top-N recommendations\n",
    "watched = {}\n",
    "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust (1990) 8.993195870740706\n",
      "Night Porter, The (Portiere di notte, Il) (1974) 8.991602228017534\n",
      "Daytrippers, The (1996) 8.978892697759282\n",
      "Living in Oblivion (1995) 8.973090760365785\n",
      "Melvin and Howard (1980) 8.970142500145332\n",
      "Hate (Haine, La) (1995) 8.967270202229166\n",
      "Presidio, The (1988) 8.96429313204702\n",
      "Stop Making Sense (1984) 8.954691793826552\n",
      "Color Purple, The (1985) 8.954276360003217\n",
      "Opposite of Sex, The (1998) 8.95170801390616\n",
      "Clue (1985) 8.949644625955322\n"
     ]
    }
   ],
   "source": [
    "# Get top-rated items from similar users:\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainSet.to_raw_iid(itemID)\n",
    "        print(ml.getMovieName(int(movieID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning collaborative filtering algorithms\n",
    "\n",
    "There are many ways to implement user-based and item-based collaborative filtering. One thing I'm doing that's kind of arbitrary is pulling off the top 10 highest-rated items for a user when generating item-based recommendations or the top 10 most similar users when finding user-based recommendations. That seems like kind of an arbitrary cut off. Maybe it would be better if instead of taking the top-k sources for recommendation candidates, we just used any source above some given quality threshold. For example, maybe any item a user rated higher than four stars should generate item-based recommendation candidates no matter how many or how few of them there may be. Or (for user-based collaborative filtering) any comparison user that has a cosine similarity greater than 0.95 should be used to generate candidates in the user-based recommendations. \n",
    "\n",
    "I try that approach below, proceeding from the line of code that generated the top-k highest-rated movies from our test user and and replaced it with code that goes through and adds any rating above four stars to the list of movies that generate recommendation candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Opposite of Sex, The (1998) 10.94172656584623\n",
      "American in Paris, An (1951) 10.936427200000246\n",
      "One Fine Day (1996) 10.934890689782453\n",
      "Last Picture Show, The (1971) 10.931806486265977\n",
      "Gilda (1946) 10.929912059633953\n",
      "Dead Calm (1989) 10.916981536391042\n",
      "Streetcar Named Desire, A (1951) 10.91594253451208\n",
      "Five Easy Pieces (1970) 10.914690389589753\n",
      "Out of the Past (1947) 10.910660929932783\n",
      "Killer, The (Die xue shuang xiong) (1989) 10.90933848448976\n",
      "Born Yesterday (1950) 10.909227888131605\n"
     ]
    }
   ],
   "source": [
    "testSubject = '85'\n",
    "k = 10\n",
    "\n",
    "ml = MovieLens()\n",
    "data = ml.loadMovieLensLatestSmall()\n",
    "trainSet = data.build_full_trainset()\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': False\n",
    "               }\n",
    "\n",
    "model = KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()\n",
    "\n",
    "testUserRatings = trainSet.ur[testUserInnerID]\n",
    "\n",
    "###\n",
    "kNeighbors = []\n",
    "for rating in testUserRatings:\n",
    "    if rating[1]> 4.0:\n",
    "        kNeighbors.append(rating)\n",
    "###\n",
    "        \n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "        candidates[innerID] += score * (rating / 5.0)\n",
    "        \n",
    "watched = {}\n",
    "for itemID, rating in trainSet.ur[testUserInnerID]:\n",
    "    watched[itemID] = 1\n",
    "\n",
    "pos = 0\n",
    "for itemID, ratingSum in sorted(candidates.items(), key=itemgetter(1), reverse=True):\n",
    "    if not itemID in watched:\n",
    "        movieID = trainSet.to_raw_iid(itemID)\n",
    "        print(ml.getMovieName(int(movieID)), ratingSum)\n",
    "        pos += 1\n",
    "        if (pos > 10):\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say which set of results is better, but what's very noticeable is how different these lists are. We do see some of the same movies being included such as 'The opposite of Sex' but many recommendations from the previous method are totally gone here. With this change, it looks like I've displaced many of the original results with different titles. To see if this might be a promising change, we'd have to test on real users and see how they interact with their recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
